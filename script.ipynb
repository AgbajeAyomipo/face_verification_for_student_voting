{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Ayo Agbaje\\my_venv_\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import tqdm\n",
    "from tqdm.auto import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "\n",
    "import deepface\n",
    "from deepface import DeepFace\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['VGG-Face', 'Facenet', 'Facenet512', 'openFace', 'DeepFace', 'DeepId', 'ArcFace', 'Dlib', 'SFace']\n",
    "backends = ['opencv', 'ssd', 'dlib', 'mtcnn', 'retinaface', 'mediapipe']\n",
    "\n",
    "result = DeepFace.verify(\n",
    "    img1_path = 'records/CYS-18-5884/1721675648162.jpg',\n",
    "    img2_path = 'records/CYS-18-8479/1721675646498.jpg',\n",
    "    model_name = models[1],\n",
    "    distance_metric = 'cosine',\n",
    "    enforce_detection = False,\n",
    "    detector_backend = backends[0],\n",
    "    align = False,\n",
    "    threshold = .2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verified': False,\n",
       " 'distance': 0.8278660258791868,\n",
       " 'threshold': 0.2,\n",
       " 'model': 'Facenet',\n",
       " 'detector_backend': 'opencv',\n",
       " 'similarity_metric': 'cosine',\n",
       " 'facial_areas': {'img1': {'x': 0,\n",
       "   'y': 0,\n",
       "   'w': 1459,\n",
       "   'h': 2210,\n",
       "   'left_eye': None,\n",
       "   'right_eye': None},\n",
       "  'img2': {'x': 0,\n",
       "   'y': 0,\n",
       "   'w': 1664,\n",
       "   'h': 2639,\n",
       "   'left_eye': None,\n",
       "   'right_eye': None}},\n",
       " 'time': 8.36}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13346d4bce04924a03b289d7ff4cd44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b56cc2eaf447d4b6290aef07cae2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat_no = list()\n",
    "for i in tqdm(os.listdir(\"records\")):\n",
    "    mat_no.append(\"/\".join(i.split(\"-\")))\n",
    "\n",
    "\n",
    "img_path = list()\n",
    "for i in tqdm(os.listdir(\"records\")):\n",
    "    record_ = f\"records/{i}\"\n",
    "    rec_ = list()\n",
    "    for n, j in enumerate((os.listdir(record_))):\n",
    "        rec_.append(f\"records/{i}/{j}\")\n",
    "    img_path.append(\" \".join(rec_))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 15)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_path), len(mat_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_df = pd.DataFrame(\n",
    "    data = {\n",
    "        \"matric number\": mat_no,\n",
    "        \"img paths\": img_path\n",
    "    }\n",
    ")\n",
    "records_df.head()\n",
    "records_df.to_csv(\"records.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matric number found in Database\n"
     ]
    }
   ],
   "source": [
    "# simple python workflow\n",
    "\n",
    "mat_no_ = input(\"Input Matric No here(DEPT/YY/NNNN).....\")\n",
    "student_name = input(\"Input your name here.......\")\n",
    "\n",
    "df = pd.read_csv(\"records.csv\")\n",
    "mat_nos = [i for i in df[\"matric number\"].values]\n",
    "\n",
    "if mat_no_ in mat_nos:\n",
    "    print(\"Matric number found in Database\")\n",
    "    verified = True\n",
    "else:\n",
    "    print(\"Student matric number not found in database\")\n",
    "    verified = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verified:\n",
    "    df_sort = df[df[\"matric number\"] == mat_no_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matric number</th>\n",
       "      <th>img paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CYS/18/5874</td>\n",
       "      <td>records/CYS-18-5874/1721676589154.jpg records/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  matric number                                          img paths\n",
       "0   CYS/18/5874  records/CYS-18-5874/1721676589154.jpg records/..."
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['records/CYS-18-5874/1721676589154.jpg',\n",
       " 'records/CYS-18-5874/1721676589194.jpg']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_ = df_sort[\"img paths\"].values[0]\n",
    "imgs = imgs_.split(\" \")\n",
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ = image.imread('records/CYS-18-8472/1721675648545.jpg')\n",
    "# img_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_status = list()\n",
    "for img in imgs:\n",
    "    result = DeepFace.verify(\n",
    "        img1_path = img_,\n",
    "        img2_path = img,\n",
    "        model_name = models[1],\n",
    "        distance_metric = 'cosine',\n",
    "        enforce_detection = False,\n",
    "        detector_backend = backends[0],\n",
    "        align = False,\n",
    "        threshold = .2\n",
    "    )\n",
    "\n",
    "    verify_status.append(result[\"verified\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify_status.index(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Ayo Agbaje\\my_venv_\\lib\\site-packages\\gradio\\routes.py\", line 422, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\Ayo Agbaje\\my_venv_\\lib\\site-packages\\gradio\\blocks.py\", line 1326, in process_api\n",
      "    data = self.postprocess_data(fn_index, result[\"prediction\"], state)\n",
      "  File \"c:\\Users\\Ayo Agbaje\\my_venv_\\lib\\site-packages\\gradio\\blocks.py\", line 1260, in postprocess_data\n",
      "    prediction_value = block.postprocess(prediction_value)\n",
      "  File \"c:\\Users\\Ayo Agbaje\\my_venv_\\lib\\site-packages\\gradio\\components.py\", line 1868, in postprocess\n",
      "    raise ValueError(\"Cannot process this value as an Image\")\n",
      "ValueError: Cannot process this value as an Image\n"
     ]
    }
   ],
   "source": [
    "def image_predict(mat_no_, student_name, img_):\n",
    "    models = ['VGG-Face', 'Facenet', 'Facenet512', 'openFace', 'DeepFace', 'DeepId', 'ArcFace', 'Dlib', 'SFace']\n",
    "    backends = ['opencv', 'ssd', 'dlib', 'mtcnn', 'retinaface', 'mediapipe']\n",
    "    df = pd.read_csv(\"records.csv\")\n",
    "    mat_nos = [i for i in df[\"matric number\"].values]\n",
    "\n",
    "    if mat_no_ in mat_nos:\n",
    "        verified = True\n",
    "    else:\n",
    "        verified = False\n",
    "    \n",
    "    if verified:\n",
    "        df_sort = df[df[\"matric number\"] == mat_no_]\n",
    "        imgs_ = df_sort[\"img paths\"].values[0]\n",
    "        imgs = imgs_.split(\" \")\n",
    "\n",
    "        verify_status = list()\n",
    "        for img in imgs:\n",
    "            result = DeepFace.verify(\n",
    "                img1_path = img_,\n",
    "                img2_path = img,\n",
    "                model_name = models[1],\n",
    "                distance_metric = 'cosine',\n",
    "                enforce_detection = False,\n",
    "                detector_backend = backends[0],\n",
    "                align = False,\n",
    "                threshold = .2\n",
    "            )\n",
    "\n",
    "        verify_status.append(result[\"verified\"])\n",
    "\n",
    "        if True in verify_status:\n",
    "            response_ = f\"{student_name} verified\"\n",
    "            img_match_id = imgs.index(True)\n",
    "            img_match = imgs[img_match_id]\n",
    "            img_match = gr.Image(value = \"no_img.jpg\")\n",
    "\n",
    "            return response_, img_match\n",
    "        else:\n",
    "            response_ = f\"{student_name} not verified(does not match image in the Database)\"\n",
    "            img_match = gr.Image(value = img_)\n",
    "            return response_, img_match\n",
    "    else:\n",
    "        response__ = f\"{student_name} not found in Database\"\n",
    "        img_match = gr.Image(value = \"no_img.jpg\")\n",
    "        \n",
    "        return response__, img_match\n",
    "    \n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    m_no = gr.Textbox(label = \"Input Matric No here(DEPT/YY/NNNN).....\")\n",
    "    name_ = gr.Textbox(label = \"Input your name here.......\")\n",
    "    image_ = gr.Image(label = 'Input Image to be predicted', source = \"webcam\")\n",
    "    output1 = gr.Textbox(label = 'Response')\n",
    "    output2 = gr.Image()\n",
    "    btn = gr.Button('Verify')\n",
    "    btn.click(fn = image_predict, inputs = [m_no, name_, image_], outputs = [output1, output2])\n",
    "\n",
    "demo.launch(share = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
